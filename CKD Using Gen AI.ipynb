{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb11effa-1487-4a28-bb4e-8014eaf3a3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   age         bp sg   al   su     rbc        pc         pcc          ba  \\\n",
      "0  2.0  76.459948  c  3.0  0.0  normal  abnormal  notpresent  notpresent   \n",
      "1  3.0  76.459948  c  2.0  0.0  normal    normal  notpresent  notpresent   \n",
      "2  4.0  76.459948  a  1.0  0.0  normal    normal  notpresent  notpresent   \n",
      "3  5.0  76.459948  d  1.0  0.0  normal    normal  notpresent  notpresent   \n",
      "4  5.0  50.000000  c  0.0  0.0  normal    normal  notpresent  notpresent   \n",
      "\n",
      "          bgr  ...        pcv            wc        rc  htn  dm  cad  appet  \\\n",
      "0  148.112676  ...  38.868902   8408.191126  4.705597   no  no   no    yes   \n",
      "1  148.112676  ...  34.000000  12300.000000  4.705597   no  no   no    yes   \n",
      "2   99.000000  ...  34.000000   8408.191126  4.705597   no  no   no    yes   \n",
      "3  148.112676  ...  38.868902   8408.191126  4.705597   no  no   no    yes   \n",
      "4  148.112676  ...  36.000000  12400.000000  4.705597   no  no   no    yes   \n",
      "\n",
      "     pe  ane classification  \n",
      "0   yes   no            yes  \n",
      "1  poor   no            yes  \n",
      "2  poor   no            yes  \n",
      "3  poor  yes            yes  \n",
      "4  poor   no            yes  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Dataset shape (rows, columns): (399, 25)\n",
      "\n",
      "Column info:\n",
      "age               float64\n",
      "bp                float64\n",
      "sg                 object\n",
      "al                float64\n",
      "su                float64\n",
      "rbc                object\n",
      "pc                 object\n",
      "pcc                object\n",
      "ba                 object\n",
      "bgr               float64\n",
      "bu                float64\n",
      "sc                float64\n",
      "sod               float64\n",
      "pot               float64\n",
      "hrmo              float64\n",
      "pcv               float64\n",
      "wc                float64\n",
      "rc                float64\n",
      "htn                object\n",
      "dm                 object\n",
      "cad                object\n",
      "appet              object\n",
      "pe                 object\n",
      "ane                object\n",
      "classification     object\n",
      "dtype: object\n",
      "\n",
      "Summary statistics:\n",
      "               age          bp   sg          al          su     rbc      pc  \\\n",
      "count   399.000000  399.000000  399  399.000000  399.000000     399     399   \n",
      "unique         NaN         NaN    5         NaN         NaN       2       2   \n",
      "top            NaN         NaN    a         NaN         NaN  normal  normal   \n",
      "freq           NaN         NaN  152         NaN         NaN     352     323   \n",
      "mean     51.492308   76.459948  NaN    0.899749    0.395990     NaN     NaN   \n",
      "std      16.995379   13.492053  NaN    1.314769    1.041155     NaN     NaN   \n",
      "min       2.000000   50.000000  NaN    0.000000    0.000000     NaN     NaN   \n",
      "25%      42.000000   70.000000  NaN    0.000000    0.000000     NaN     NaN   \n",
      "50%      54.000000   76.459948  NaN    0.000000    0.000000     NaN     NaN   \n",
      "75%      64.000000   80.000000  NaN    2.000000    0.000000     NaN     NaN   \n",
      "max      90.000000  180.000000  NaN    5.000000    5.000000     NaN     NaN   \n",
      "\n",
      "               pcc          ba         bgr  ...         pcv            wc  \\\n",
      "count          399         399  399.000000  ...  399.000000    399.000000   \n",
      "unique           2           2         NaN  ...         NaN           NaN   \n",
      "top     notpresent  notpresent         NaN  ...         NaN           NaN   \n",
      "freq           357         377         NaN  ...         NaN           NaN   \n",
      "mean           NaN         NaN  148.112676  ...   38.868902   8408.191126   \n",
      "std            NaN         NaN   74.864224  ...    8.157274   2526.204544   \n",
      "min            NaN         NaN   22.000000  ...    9.000000   2200.000000   \n",
      "25%            NaN         NaN  101.000000  ...   34.000000   6950.000000   \n",
      "50%            NaN         NaN  127.000000  ...   38.868902   8408.191126   \n",
      "75%            NaN         NaN  150.000000  ...   44.000000   9400.000000   \n",
      "max            NaN         NaN  490.000000  ...   54.000000  26400.000000   \n",
      "\n",
      "                rc  htn   dm  cad  appet    pe  ane classification  \n",
      "count   399.000000  399  399  399    399   399  399            399  \n",
      "unique         NaN    2    2    2      2     2    2              2  \n",
      "top            NaN   no   no   no    yes  poor   no            yes  \n",
      "freq           NaN  253  263  365    316   322  339            249  \n",
      "mean      4.705597  NaN  NaN  NaN    NaN   NaN  NaN            NaN  \n",
      "std       0.841006  NaN  NaN  NaN    NaN   NaN  NaN            NaN  \n",
      "min       2.100000  NaN  NaN  NaN    NaN   NaN  NaN            NaN  \n",
      "25%       4.500000  NaN  NaN  NaN    NaN   NaN  NaN            NaN  \n",
      "50%       4.705597  NaN  NaN  NaN    NaN   NaN  NaN            NaN  \n",
      "75%       5.100000  NaN  NaN  NaN    NaN   NaN  NaN            NaN  \n",
      "max       8.000000  NaN  NaN  NaN    NaN   NaN  NaN            NaN  \n",
      "\n",
      "[11 rows x 25 columns]\n",
      "\n",
      "Missing values in each column:\n",
      "age               0\n",
      "bp                0\n",
      "sg                0\n",
      "al                0\n",
      "su                0\n",
      "rbc               0\n",
      "pc                0\n",
      "pcc               0\n",
      "ba                0\n",
      "bgr               0\n",
      "bu                0\n",
      "sc                0\n",
      "sod               0\n",
      "pot               0\n",
      "hrmo              0\n",
      "pcv               0\n",
      "wc                0\n",
      "rc                0\n",
      "htn               0\n",
      "dm                0\n",
      "cad               0\n",
      "appet             0\n",
      "pe                0\n",
      "ane               0\n",
      "classification    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('CKD.csv')\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(\"\\nDataset shape (rows, columns):\", df.shape)\n",
    "\n",
    "# Display column names and data types\n",
    "print(\"\\nColumn info:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9718ac73-ef37-4c2d-98b6-a8e0928090ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n",
      "       'sc', 'sod', 'pot', 'hrmo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n",
      "       'appet', 'pe', 'ane', 'classification'],\n",
      "      dtype='object')\n",
      "✅ Done. Ready for model building!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Step 1: Load Data\n",
    "df = pd.read_csv(\"CKD.csv\")\n",
    "\n",
    "# Step 2: Clean Column Names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Step 3: Fix Target Column\n",
    "# Find the actual column name\n",
    "print(df.columns)\n",
    "\n",
    "# Let's assume it is named 'classification'\n",
    "df['classification'] = df['classification'].astype(str).str.strip().str.lower()\n",
    "df['classification'] = df['classification'].replace({'ckd': 1, 'notckd': 0})\n",
    "\n",
    "# Step 4: Replace ? and other missing symbols with NaN\n",
    "df.replace(['?', 'nan', 'null', 'na'], np.nan, inplace=True)\n",
    "\n",
    "# Step 5: Convert all possible columns to numeric\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Step 6: Fill missing values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Step 7: Encode categorical columns\n",
    "label = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = label.fit_transform(df[col])\n",
    "\n",
    "# Step 8: Define X and y\n",
    "X = df.drop('classification', axis=1)\n",
    "y = df['classification']\n",
    "\n",
    "# Step 9: Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 10: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"✅ Done. Ready for model building!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3db4456d-7e0c-4151-9553-98688e4e3404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Evaluating Logistic Regression...\n",
      "\n",
      "Best Parameters: {'C': 0.01, 'solver': 'lbfgs'}\n",
      "Accuracy: 0.975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        39\n",
      "           1       0.98      0.98      0.98        41\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.97      0.97      0.97        80\n",
      "weighted avg       0.97      0.97      0.97        80\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38  1]\n",
      " [ 1 40]]\n",
      "\n",
      "📌 Evaluating K-Nearest Neighbors...\n",
      "\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Accuracy: 0.9375\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        39\n",
      "           1       0.97      0.90      0.94        41\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.94      0.94      0.94        80\n",
      "weighted avg       0.94      0.94      0.94        80\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38  1]\n",
      " [ 4 37]]\n",
      "\n",
      "📌 Evaluating Decision Tree...\n",
      "\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 2}\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "Confusion Matrix:\n",
      " [[39  0]\n",
      " [ 0 41]]\n",
      "\n",
      "📌 Evaluating Random Forest...\n",
      "\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "Confusion Matrix:\n",
      " [[39  0]\n",
      " [ 0 41]]\n",
      "\n",
      "📌 Evaluating Support Vector Machine...\n",
      "\n",
      "Best Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.9875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       0.98      1.00      0.99        41\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.99      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38  1]\n",
      " [ 0 41]]\n",
      "\n",
      "📌 Evaluating Naive Bayes...\n",
      "\n",
      "Accuracy: 0.9625\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        39\n",
      "           1       0.97      0.95      0.96        41\n",
      "\n",
      "    accuracy                           0.96        80\n",
      "   macro avg       0.96      0.96      0.96        80\n",
      "weighted avg       0.96      0.96      0.96        80\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38  1]\n",
      " [ 2 39]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "models_results = {}\n",
    "\n",
    "def evaluate_model(model, params, model_name):\n",
    "    print(f\"\\n📌 Evaluating {model_name}...\\n\")\n",
    "    \n",
    "    if params:\n",
    "        grid = GridSearchCV(model, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        print(\"Best Parameters:\", grid.best_params_)\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Store results\n",
    "    models_results[model_name] = {\n",
    "        'model': best_model,\n",
    "        'accuracy': acc\n",
    "    }\n",
    "\n",
    "# 1. Logistic Regression\n",
    "evaluate_model(LogisticRegression(max_iter=1000), {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}, \"Logistic Regression\")\n",
    "\n",
    "# 2. K-Nearest Neighbors\n",
    "evaluate_model(KNeighborsClassifier(), {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}, \"K-Nearest Neighbors\")\n",
    "\n",
    "# 3. Decision Tree\n",
    "evaluate_model(DecisionTreeClassifier(), {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}, \"Decision Tree\")\n",
    "\n",
    "# 4. Random Forest\n",
    "evaluate_model(RandomForestClassifier(), {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}, \"Random Forest\")\n",
    "\n",
    "# 5. Support Vector Machine\n",
    "evaluate_model(SVC(), {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}, \"Support Vector Machine\")\n",
    "\n",
    "# 6. Naive Bayes (no hyperparameters needed for GaussianNB)\n",
    "evaluate_model(GaussianNB(), None, \"Naive Bayes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eed0637-c491-47cf-878d-d9e19eb19bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Comparison Summary:\n",
      "                    Model  Accuracy  \\\n",
      "0           Decision Tree    1.0000   \n",
      "1           Random Forest    1.0000   \n",
      "2  Support Vector Machine    0.9875   \n",
      "3     Logistic Regression    0.9750   \n",
      "4             Naive Bayes    0.9625   \n",
      "5     K-Nearest Neighbors    0.9375   \n",
      "\n",
      "                                     Best Parameters  \n",
      "0  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
      "1  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
      "2  {'C': 10, 'break_ties': False, 'cache_size': 2...  \n",
      "3  {'C': 0.01, 'class_weight': None, 'dual': Fals...  \n",
      "4           {'priors': None, 'var_smoothing': 1e-09}  \n",
      "5  {'algorithm': 'auto', 'leaf_size': 30, 'metric...  \n"
     ]
    }
   ],
   "source": [
    "# Convert results into a DataFrame for easy comparison\n",
    "results_df = pd.DataFrame([\n",
    "    {'Model': model, \n",
    "     'Accuracy': round(models_results[model]['accuracy'], 4),\n",
    "     'Best Parameters': str(models_results[model]['model'].get_params())}\n",
    "    for model in models_results\n",
    "])\n",
    "\n",
    "# Sort by accuracy\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Show the comparison table\n",
    "print(\"📊 Model Comparison Summary:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f53fe1d-32c2-4a0b-9c41-31cb11013eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅📊🚀🔍📌🧠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e88e5-cb29-42ad-8fd3-31e1e74bdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Model Selection & Justification\n",
    "#Choose the best-performing model from your table based on accuracy and consistency:\n",
    "\n",
    "#✅ Justification Example (You can copy/edit for your report):\n",
    "#After evaluating all six classification models, the Random Forest Classifier achieved the highest accuracy (98.24%) \n",
    "#with optimized hyperparameters. It performed consistently well across all metrics (precision, recall, F1-score)\n",
    "# and was robust to overfitting due to ensemble averaging. Hence, Random Forest was selected as the final model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
